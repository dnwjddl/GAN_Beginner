- 순환 신경망으로 특정 글의 스타일을 흉내낸 텍스트 seq를 생성하는데 적용
- 문장에서 가능한 질문-대답 쌍 생성

# RNN(처음)
- 순환층은 매우 간단
- tanh() 하나로 구성(time step사이에 정보를 -1~1사이로 scale 맞춤
  - gradient Vanishing(그레이디언트 소실) : **긴 sequence 가진 데이터에 안 좋음**
***RNN은 격차가 늘수록 학습 정보를 잃어버림***
